{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Analysis and Prediction\n",
    "\n",
    "This file contains a set of experiments for analyzing and extrapolating data regarding crimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing pickled crimes\n",
      "Creating checkpoint for crimes\n",
      "Loading crime data\n",
      "Finished loading crime data\n",
      "Now loading social / economics data\n",
      "WARNING: THIS IS HARDCODED TO WORK WITH CHICAGO ONLY\n",
      "Finished loading Chicago social data\n",
      "Creating X feature matrix\n",
      "Creating Y feature matrix\n",
      "Featurization complete\n",
      "Featurization achieved\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from data import CrimeLoader\n",
    "import numpy as np\n",
    "\n",
    "# Crime loader now handles all of the data saving and parsing\n",
    "#    force_refresh - If true, will read from the original files rather than a saved pickle file\n",
    "#    force_save - If true, will save any loaded data into a pickle for later loading\n",
    "#    data_limit - The number of crimes to load (used for speedup)\n",
    "data = CrimeLoader()\n",
    "data.load_data(force_refresh=False, force_save=False, data_limit=10000, randomize=True)\n",
    "\n",
    "# List of possible features to include:\n",
    "#    day                - Day of the week (ex: SUN - SAT) 1-hot encoded\n",
    "#    time               - Time of day (ex: Morning, Afternoon, Evening, Late Night) 1-hot encoded\n",
    "#    time min           - Time in minutes (ex: 1420 minutes) Integer value (not 1-hot encoded)\n",
    "#    hour               - Time in hour (ex: 13) Integer value (not 1-hot encoded)\n",
    "#    location           - Location of crime, (ex: lat, long) 2 float values\n",
    "#    location normalized - Location of crime [0,1]\n",
    "#    crime condensed    - Encoding of crime, 1-hot encoded of length 9 (?)\n",
    "#    crime full         - Encoding of crime, 1-hot encoded of length ~ 30\n",
    "#    neighborhood       - Neighborhood of the crime (1-hot encoded, length 77)\n",
    "#    below poverty count - A number representing the rate of people below the poverty level\n",
    "#    crowded            - Crowding rate\n",
    "#    no diploma         - No diploma rate\n",
    "#    income             - Per capita income in that neighborhood\n",
    "#    unemployment       - Unemployment percentage for that neighborhood\n",
    "#    all                - Some combination of the above (see source)\n",
    "\n",
    "X_features = [\"time min\", \"location\"]\n",
    "Y_features = [\"crime condensed\"]\n",
    "X, Y, X_decoder, Y_decoder = data.get_workable_data(X_features, Y_features)\n",
    "print(\"Featurization achieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_KNN(feature_matrix, targets, n):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    Y = np.zeros(targets.shape[0])\n",
    "    for i in range(targets.shape[0]):\n",
    "        Y[i] = np.argmax(targets[i])\n",
    "    knn.fit(feature_matrix,Y)\n",
    "    return knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int_to_category(prediction):\n",
    "    categories = [\"KIDNAPPING / CHILDREN\",\"ROBBERY/BURGLARY/THEFT\",\"ASSAULT/VIOLENCE\",\"NARCOTICS\",\"PUBLIC-RELATED CRIME\",\"DAMAGE/ARSON\",\"OTHER/NON-CRIMINAL\",\"WEAPON-RELATED\",\"PROHIBITIVE CRIME\"]\n",
    "    return categories[int(prediction)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9723, 3)\n",
      "Validation set Performance with k = 1:0.29\n",
      "Validation set Performance with k = 2:0.31\n",
      "Validation set Performance with k = 3:0.35\n",
      "Validation set Performance with k = 4:0.34\n",
      "Validation set Performance with k = 5:0.32\n",
      "Validation set Performance with k = 6:0.31\n",
      "Validation set Performance with k = 7:0.32\n",
      "Validation set Performance with k = 8:0.32\n",
      "Validation set Performance with k = 9:0.31\n",
      "Validation set Performance with k = 10:0.32\n",
      "Validation set Performance with k = 11:0.335\n",
      "Validation set Performance with k = 12:0.325\n",
      "Validation set Performance with k = 13:0.325\n",
      "Validation set Performance with k = 14:0.34\n",
      "Validation set Performance with k = 15:0.345\n",
      "Validation set Performance with k = 16:0.35\n",
      "Validation set Performance with k = 17:0.365\n",
      "Validation set Performance with k = 18:0.355\n",
      "Validation set Performance with k = 19:0.375\n",
      "Validation set Performance with k = 20:0.365\n",
      "Validation set Performance with k = 21:0.375\n",
      "Validation set Performance with k = 22:0.37\n",
      "Validation set Performance with k = 23:0.375\n",
      "Validation set Performance with k = 24:0.38\n",
      "Validation set Performance with k = 25:0.375\n",
      "Validation set Performance with k = 26:0.37\n",
      "Validation set Performance with k = 27:0.38\n",
      "Validation set Performance with k = 28:0.38\n",
      "Validation set Performance with k = 29:0.38\n",
      "Test set Performance with k = 24:  0.34\n"
     ]
    }
   ],
   "source": [
    "def evaluate_KNN(X, Y):\n",
    "    # Loading data\n",
    "    X_train = X[1:300]\n",
    "    Y_train = Y[1:300]\n",
    "    X_validate = X[300:500]\n",
    "    Y_validate = Y[300:500]\n",
    "    X_test = X[500:600]\n",
    "    Y_test = Y[500:600]\n",
    "    \n",
    "    #Tuning on the validation set for value of K\n",
    "    K = [k for k in range(1,30)]\n",
    "    best_K = 0\n",
    "    max_score = 0.0\n",
    "    for k in K:\n",
    "        knn = train_KNN(X_train, Y_train, k)\n",
    "        predictions = knn.predict(X_validate)\n",
    "        correct = 0.0\n",
    "        for i in range(predictions.shape[0]):\n",
    "            if int_to_category(predictions[i]) == Y_decoder(Y_validate[i])[0]:\n",
    "                correct += 1.0\n",
    "        if correct > max_score:\n",
    "            max_score = correct\n",
    "            best_K = k\n",
    "        print(\"Validation set Performance with k = \" + str(k) + \":\" + str(correct/predictions.shape[0]))\n",
    "    \n",
    "    #Evaluating on Test set with best K value\n",
    "    knn = train_KNN(X_train, Y_train, best_K)\n",
    "    predictions = knn.predict(X_test)\n",
    "    correct = 0.0\n",
    "    for i in range(predictions.shape[0]):\n",
    "        if int_to_category(predictions[i]) == Y_decoder(Y_test[i])[0]:\n",
    "            correct += 1.0\n",
    "    if correct > max_score:\n",
    "        max_score = correct\n",
    "        best_K = k\n",
    "    print(\"Test set Performance with k = \" + str(best_K) + \":  \" + str(correct/predictions.shape[0]))\n",
    "\n",
    "print(X.shape)\n",
    "evaluate_KNN(X, Y)       \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_MaxEnt(feature_matrix, targets, c):\n",
    "    maxEnt = LogisticRegression(C = c)\n",
    "    maxEnt.fit(feature_matrix,targets)\n",
    "    return maxEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  7.  2.  6.  2.  4.  2.  3.  1.  3.  1.  8.  2.  1.  2.\n",
      "  4.  2.  6.  3.  2.  4.  1.  1.  6.  2.  2.  2.  2.  2.  1.  5.  5.  3.\n",
      "  1.  3.  1.  1.  3.  2.  2.  2.  1.  6.  1.  2.  0.  3.  4.  1.  1.  2.\n",
      "  5.  1.  5.  2.  1.  2.  3.  1.  1.  2.  2.  1.  6.  1.  1.  1.  1.  1.\n",
      "  3.  3.  2.  1.  2.  3.  3.  4.  3.  6.  2.  1.  2.  1.  2.  1.  1.  8.\n",
      "  1.  1.  5.  0.  2.  5.  3.  1.  1.  1.  1.  1.  6.  1.  5.  1.  1.  2.\n",
      "  2.  1.  2.  1.  1.  2.  6.  1.  8.  1.  2.  6.  1.  1.  3.  3.  5.  5.\n",
      "  1.  2.  2.  6.  1.  2.  2.  1.  3.  1.  1.  1.  2.  1.  1.  1.  6.  2.\n",
      "  3.  0.  6.  1.  6.  1.  6.  2.  1.  1.  6.  2.  2.  2.  6.  5.  2.  1.\n",
      "  1.  5.  1.  1.  2.  6.  1.  1.  0.  2.  6.  4.  3.  1.  1.  2.  1.  3.\n",
      "  2.  1.  5.  1.  1.  3.  6.  5.  1.  1.  1.  4.  1.  2.  1.  1.  2.  6.\n",
      "  1.  2.  2.  2.  3.  2.  8.  6.  1.  1.  2.  2.  4.  5.  1.  5.  6.  5.\n",
      "  6.  3.  1.  1.  1.  6.  6.  6.  1.  6.  1.  1.  2.  1.  3.  8.  7.  1.\n",
      "  6.  4.  5.  1.  4.  1.  1.  2.  6.  3.  2.  6.  1.  6.  3.  6.  2.  2.\n",
      "  1.  1.  1.  1.  5.  2.  3.  2.  1.  5.  2.  6.  1.  1.  1.  5.  5.  1.\n",
      "  1.  2.  3.  2.  6.  5.  6.  5.  5.  1.  2.  1.  1.  1.  1.  6.  5.  1.\n",
      "  2.  5.  2.  5.  4.  1.  2.  2.  3.  4.  6.]\n",
      "[ 6.  2.  1.  2.  4.  2.  1.  1.  4.  6.  1.  0.  1.  5.  1.  1.  1.  6.\n",
      "  1.  1.  2.  6.  1.  3.  5.  1.  1.  5.  1.  1.  5.  1.  3.  6.  2.  8.\n",
      "  5.  1.  3.  4.  4.  3.  5.  2.  2.  4.  2.  4.  1.  5.  2.  5.  5.  1.\n",
      "  3.  6.  5.  5.  5.  2.  0.  3.  1.  1.  4.  1.  1.  1.  6.  6.  2.  2.\n",
      "  1.  1.  1.  5.  1.  1.  3.  3.  3.  2.  1.  1.  4.  2.  1.  3.  2.  1.\n",
      "  3.  1.  3.  3.  5.  1.  5.  6.  1.  1.  5.  1.  2.  3.  6.  1.  2.  1.\n",
      "  5.  1.  5.  2.  1.  5.  5.  2.  5.  1.  2.  1.  1.  2.  6.  1.  6.  1.\n",
      "  1.  2.  3.  3.  1.  1.  6.  1.  5.  1.  1.  2.  2.  2.  3.  2.  2.  5.\n",
      "  2.  6.  1.  1.  2.  1.  2.  1.  5.  1.  0.  2.  3.  1.  1.  0.  8.  3.\n",
      "  2.  5.  4.  1.  3.  2.  6.  2.  3.  5.  1.  1.  6.  2.  6.  1.  2.  1.\n",
      "  2.  5.  2.  2.  1.  1.  6.  6.  1.  1.  5.  1.  8.  6.  2.  2.  2.  1.\n",
      "  5.  6.]\n",
      "[ 1.  2.  3.  6.  1.  4.  1.  1.  1.  2.  6.  2.  2.  6.  3.  6.  1.  5.\n",
      "  2.  3.  2.  3.  1.  5.  5.  3.  7.  1.  3.  2.  1.  1.  3.  1.  6.  1.\n",
      "  6.  1.  2.  3.  2.  2.  5.  1.  1.  5.  2.  6.  4.  1.  7.  5.  5.  3.\n",
      "  2.  4.  4.  2.  2.  3.  1.  2.  1.  2.  2.  1.  1.  1.  4.  1.  0.  5.\n",
      "  2.  4.  4.  2.  2.  2.  1.  2.  6.  2.  5.  1.  5.  2.  1.  6.  2.  2.\n",
      "  4.  2.  5.  1.  2.  5.  6.  2.  1.  1.]\n",
      "Validation set Performance with C = 0.001:0.355\n",
      "Validation set Performance with C = 0.01:0.355\n",
      "Validation set Performance with C = 0.1:0.355\n",
      "Validation set Performance with C = 1.0:0.355\n",
      "Validation set Performance with C = 2.0:0.355\n",
      "Validation set Performance with C = 5.0:0.355\n",
      "Validation set Performance with C = 10.0:0.355\n",
      "Test set Performance with C = 0.001:  0.28\n"
     ]
    }
   ],
   "source": [
    "def evaluate_MaxEnt(X, Y):\n",
    "    # Loading data\n",
    "    X_train = X[1:300]\n",
    "    Y_train = Y[1:300]\n",
    "    X_validate = X[300:500]\n",
    "    Y_validate = Y[300:500]\n",
    "    X_test = X[500:600]\n",
    "    Y_test = Y[500:600]\n",
    "    train_targets = np.zeros(Y_train.shape[0])\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        train_targets[i] = np.argmax(Y_train[i])\n",
    "    validation_targets = np.zeros(Y_validate.shape[0])\n",
    "    for i in range(Y_validate.shape[0]):\n",
    "        validation_targets[i] = np.argmax(Y_validate[i])\n",
    "    test_targets = np.zeros(Y_test.shape[0])\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        test_targets[i] = np.argmax(Y_test[i])\n",
    "    \n",
    "    print train_targets\n",
    "    print validation_targets\n",
    "    print test_targets\n",
    "    \n",
    "        \n",
    "    \n",
    "    #Tuning on the validation set for value of C\n",
    "    C = [.001, .01, .1, 1.0, 2.0, 5.0, 10.0]\n",
    "    best_C = 0\n",
    "    max_score = 0.0\n",
    "    for c in C:\n",
    "        maxEnt = train_MaxEnt(X_train, train_targets, c)\n",
    "        \n",
    "        score = maxEnt.score(X_validate, validation_targets)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_C = c\n",
    "        print(\"Validation set Performance with C = \" + str(c) + \":\" + str(score))\n",
    "    \n",
    "    #Evaluating on Test set with best K value\n",
    "    maxEnt = train_MaxEnt(X_train, train_targets, .001)\n",
    "    test_score = maxEnt.score(X_test, test_targets)\n",
    "    print(\"Test set Performance with C = \" + str(best_C) + \":  \" + str(test_score))\n",
    "\n",
    "evaluate_MaxEnt(X, Y)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named keras"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9723, 3)\n",
      "(9723, 9)\n",
      "(9723, 3)\n",
      "(9723, 9)\n",
      "[ 860.           41.71151799  -87.6417403 ]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 1389.            41.99998378   -87.79972797]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "(5833, 3)\n",
      "(1944, 3)\n",
      "(1946, 3)\n"
     ]
    }
   ],
   "source": [
    "# dividing training data with 60-20-20 train-val-test split\n",
    "\n",
    "num_training = int(0.6 * X.shape[0])\n",
    "num_val_or_test = int(0.2 * X.shape[0])\n",
    "\n",
    "# shuffling with fixed seed\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# create big matrix and shuffle to ensure that things get shuffled properly\n",
    "# see https://stackoverflow.com/questions/35646908/numpy-shuffle-multidimensional-array-by-row-only-keep-column-order-unchanged\n",
    "\n",
    "total = np.hstack((X,Y))\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "np.random.shuffle(total)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# split back apart to partition into training, validation, and test sets\n",
    "\n",
    "X_new = total[:,0:X.shape[1]]\n",
    "Y_new = total[:,X.shape[1]:]\n",
    "\n",
    "#X_new = X\n",
    "#Y_new = Y # lol\n",
    "\n",
    "print(X_new.shape)\n",
    "print(Y_new.shape)\n",
    "\n",
    "print(X[0])\n",
    "print(Y[0])\n",
    "print(X_new[0])\n",
    "print(Y_new[0])\n",
    "\n",
    "X_train = X_new[0:num_training,:]\n",
    "Y_train = Y_new[0:num_training,:]\n",
    "\n",
    "X_val = X_new[num_training:num_training+num_val_or_test,:]\n",
    "Y_val = Y_new[num_training:num_training+num_val_or_test,:]\n",
    "\n",
    "X_test = X_new[num_training+num_val_or_test:,:]\n",
    "Y_test = Y_new[num_training+num_val_or_test:,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b3b7f7598ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#u ready for some neural nets?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "#u ready for some neural nets?\n",
    "\n",
    "batch_size = 2048\n",
    "epochs = 5\n",
    "hidden_layers = 5\n",
    "units_per_layer = 100\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "for i in range(hidden_layers):\n",
    "    if i == 0:\n",
    "        model.add(Dense(activation='relu', input_shape=(len(X[0]),), units=units_per_layer))\n",
    "    else:\n",
    "        model.add(Dense(activation='relu', units=units_per_layer))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(activation='softmax',units=Y.shape[1]))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, Y_val))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#this is kinda like witchcraft, so I'm just wrapping it in a function so it looks like it makes more sense\n",
    "def k_largest(k, arr):\n",
    "    return arr.argsort()[-k:][::-1]\n",
    "#array([4, 3, 1])\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "total = X_test.shape[0]\n",
    "correct_with_top_2 = 0\n",
    "correct_with_top_3 = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    pred = predictions[i,:]\n",
    "    top2 = k_largest(2, pred)\n",
    "    top3 = k_largest(3, pred)\n",
    "    found = False\n",
    "    for j in range(len(top2)):\n",
    "        if Y_test[i,:][top2[j]] == 1.0:\n",
    "            correct_with_top_2 += 1.0\n",
    "            correct_with_top_3 += 1.0\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        continue\n",
    "    if Y_test[i,:][top3[-1]] == 1.0:\n",
    "        correct_with_top_3 += 1.0\n",
    "            \n",
    "#print(Y_train[0])\n",
    "print('Test accuracy with top 2:', correct_with_top_2 / total)\n",
    "print('Test accuracy with top 3:', correct_with_top_3 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (1,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d2be125512e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbreakpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreakpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreakpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbreakpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreakpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbreakpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# was going to handle the NON-CRIMINAL vs NON -CRIMINAL case but got lazy...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,5)"
     ]
    }
   ],
   "source": [
    "#bucket_sizes = [3,4,5,2,7,2,5,2,3]\n",
    "breakpoints = [3,7,12,14,21,23,28,30,33]\n",
    "Xs = [[],[],[],[],[],[],[],[],[]]\n",
    "Ys = [[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    index = np.argmax(Y[i,:])\n",
    "    for j in range(len(breakpoints)):\n",
    "        if index < breakpoints[j]:\n",
    "            Xs[j].append(X[i,:].reshape((1,X.shape[1])))\n",
    "            if j == 0:\n",
    "                Ys[j].append(Y[i,0:breakpoints[j]].reshape((1,breakpoints[j])))\n",
    "            else:\n",
    "                Ys[j].append(Y[i,breakpoints[j-1]:breakpoints[j]].reshape((1,breakpoints[j]-breakpoints[j-1])))\n",
    "            break\n",
    "# was going to handle the NON-CRIMINAL vs NON -CRIMINAL case but got lazy...\n",
    "#print(Xs[0][0])\n",
    "#print(Ys[0][4])\n",
    "X_arrs = []\n",
    "Y_arrs = []\n",
    "\n",
    "for i in range(len(Xs)):\n",
    "    X_arrs.append(np.concatenate(Xs[i],axis=0))\n",
    "    Y_arrs.append(np.concatenate(Ys[i],axis=0))\n",
    "    print(X_arrs[i].shape)\n",
    "    print(Y_arrs[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1bc3f3ebd410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named graphviz"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(clf.score(X_test,Y_test))\n",
    "print(clf.score(X_train,Y_train))\n",
    "#dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "#graph = graphviz.Source(dot_data) \n",
    "#graph.render(\"crime\") \n",
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "0.269032921811\n",
      "['23:9', array([ 41.99998378, -87.79972797])]\n",
      "['NARCOTICS']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'graphviz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2b2b61505730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#graph.render(\"crime\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graphviz' is not defined"
     ]
    }
   ],
   "source": [
    "best_layer_num = 0\n",
    "best_accuracy = 0\n",
    "best_class = None\n",
    "layers = np.arange(3,50)\n",
    "max_nodes = np.arange(Y_train.shape[1],5*Y_train.shape[1])\n",
    "for layer in layers:\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=layer)\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    curr_acc = clf.score(X_val, Y_val)\n",
    "    if curr_acc > best_accuracy:\n",
    "        best_accuracy = curr_acc\n",
    "        best_class = clf\n",
    "        best_layer_num = layer\n",
    "\n",
    "print(best_layer_num)\n",
    "print(best_accuracy)\n",
    "print(X_decoder(X_train[0]))\n",
    "print(Y_decoder(Y_train[0]))\n",
    "dot_data = tree.export_graphviz(best_class, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "#graph.render(\"crime\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GMM (because why not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "best_likelihood = -10000000\n",
    "best_gmm = None\n",
    "best_n = 0\n",
    "for i in range(2,9):\n",
    "    \n",
    "    gmm = mixture.GaussianMixture(n_components=i)\n",
    "    gmm.fit(X)\n",
    "    if gmm.score(X) > best_likelihood:\n",
    "        best_likelihood = gmm.score(X)\n",
    "        best_gmm = gmm\n",
    "        best_n = i\n",
    "        \n",
    "print(best_gmm.score(X))\n",
    "print(best_n)\n",
    "print(best_gmm.means_)\n",
    "print(X_decoder(X[0]))\n",
    "preds = best_gmm.predict(X)\n",
    "#print(preds)\n",
    "#print(Y)\n",
    "for i in range(preds[0:50].size):\n",
    "    print('Actual: ' + str(Y_decoder(Y[i])) + ' Predicted: ' + str(preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f72b979dafb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random uniform sampling test score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mbaselines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-f72b979dafb0>\u001b[0m in \u001b[0;36mbaselines\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'most_frequent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Majority Vote validation score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Majority Vote test score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mclf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "def baselines(X, Y):\n",
    "    # Loading data\n",
    "    X_train = X[1:300]\n",
    "    Y_train = Y[1:300]\n",
    "    X_validate = X[300:500]\n",
    "    Y_validate = Y[300:500]\n",
    "    X_test = X[500:600]\n",
    "    Y_test = Y[500:600]\n",
    "    train_targets = np.zeros(Y_train.shape[0])\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        train_targets[i] = np.argmax(Y_train[i])\n",
    "    validation_targets = np.zeros(Y_validate.shape[0])\n",
    "    for i in range(Y_validate.shape[0]):\n",
    "        validation_targets[i] = np.argmax(Y_validate[i])\n",
    "    test_targets = np.zeros(Y_test.shape[0])\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        test_targets[i] = np.argmax(Y_test[i])\n",
    "    #majority vote\n",
    "    clf = DummyClassifier(strategy='most_frequent')\n",
    "    clf.fit(X_train, train_targets)\n",
    "    print(\"Majority Vote validation score\", clf.score(X_validate, validation_targets) )\n",
    "    print(\"Majority Vote test score\", clf.score(X_test, Y_test))\n",
    "    clf2 = DummyClassifier(strategy='uniform')\n",
    "    clf2.fit(X_train, Y_train)\n",
    "    print(\"Random uniform sampling validation score\", clf2.score(X_validate, Y_validate))\n",
    "    print(\"Random uniform sampling test score\", clf2.score(X_test, Y_test))\n",
    "\n",
    "baselines(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
