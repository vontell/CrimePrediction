{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Analysis and Prediction\n",
    "\n",
    "This file contains a set of experiments for analyzing and extrapolating data regarding crimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading crime data\n",
      "Saving checkpoint\n",
      "Finished loading data\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import data\n",
    "\n",
    "results = data.load_data(force_refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.]\n",
      "Test\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-22f355a88ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"time min\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_workable_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Featurization achieved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vontell/Documents/6867Crime/data.py\u001b[0m in \u001b[0;36mget_workable_data\u001b[0;34m(data, X_comps, Y_comps)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0msince\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mChicago\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mset\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude\u001b[0m \u001b[0mthose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     '''\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mX_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_specified_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_comps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mY_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_specified_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_comps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mX_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_decoder_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_comps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vontell/Documents/6867Crime/data.py\u001b[0m in \u001b[0;36mget_specified_vector\u001b[0;34m(self, comp_list)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"time min\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_time_of_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"location\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# Time test\n",
    "import data\n",
    "test = results[\"CH\"][0][0:10]\n",
    "print(test[0].time_of_day[0])\n",
    "X_features = [\"time min\"]\n",
    "Y_features = [\"location\"]\n",
    "X, Y, X_decoder, Y_decoder = data.get_workable_data(test, X_features, Y_features)\n",
    "print(\"Featurization achieved\")\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_decoder(X[0]))\n",
    "print(Y_decoder(Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: HERE IS HOW EVERYTHING WORKS!!! ------------\n",
    "#   1) Load the data using the cell above\n",
    "#   2) (Optional) If using non-condensed crimes (i.e no combination), pass\n",
    "#      a list of all crimes to save_full_crime_encoding()\n",
    "#   3) Call get_workable_data with the data from 1), pass in a list of features\n",
    "#      you want to include for X and target Y. Possible values are:\n",
    "#         \"day\" \"time\" \"location\" \"crime condensed\" \"crime full\"\n",
    "#   4) You will receive the encoded X matrix, and encoded Y matrix, and two methods\n",
    "#      for decoding the X and Y features\n",
    "\n",
    "# Use this next line for enabling the full crime set\n",
    "save_full_crime_encoding(list(set([i.crime for i in results[\"CH\"][0]])))\n",
    "\n",
    "X_features = [\"day\", \"time\", \"location\"]\n",
    "Y_features = [\"crime condensed\"]\n",
    "X, Y, X_decoder, Y_decoder = get_workable_data(results[\"CH\"][0], X_features, Y_features)\n",
    "print(\"Featurization achieved\")\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X_decoder(X[0]))\n",
    "print(Y_decoder(Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_KNN(feature_matrix, targets, n):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    Y = np.zeros(targets.shape[0])\n",
    "    for i in range(targets.shape[0]):\n",
    "        Y[i] = np.argmax(targets[i])\n",
    "    knn.fit(feature_matrix,Y)\n",
    "    return knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_category(prediction):\n",
    "    categories = [\"KIDNAPPING / CHILDREN\",\"ROBBERY/BURGLARY/THEFT\",\"ASSAULT/VIOLENCE\",\"NARCOTICS\",\"PUBLIC-RELATED CRIME\",\"DAMAGE/ARSON\",\"OTHER/NON-CRIMINAL\",\"WEAPON-RELATED\",\"PROHIBITIVE CRIME\"]\n",
    "    return categories[int(prediction)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_KNN(X, Y):\n",
    "    # Loading data\n",
    "    X_train = X[1:300]\n",
    "    Y_train = Y[1:300]\n",
    "    X_validate = X[300:500]\n",
    "    Y_validate = Y[300:500]\n",
    "    X_test = X[500:600]\n",
    "    Y_test = Y[500:600]\n",
    "    \n",
    "    #Tuning on the validation set for value of K\n",
    "    K = [k for k in range(1,30)]\n",
    "    best_K = 0\n",
    "    max_score = 0.0\n",
    "    for k in K:\n",
    "        knn = train_KNN(X_train, Y_train, k)\n",
    "        predictions = knn.predict(X_validate)\n",
    "        correct = 0.0\n",
    "        for i in range(predictions.shape[0]):\n",
    "            if int_to_category(predictions[i]) == Y_decoder(Y_validate[i])[0]:\n",
    "                correct += 1.0\n",
    "        if correct > max_score:\n",
    "            max_score = correct\n",
    "            best_K = k\n",
    "        print(\"Validation set Performance with k = \" + str(k) + \":\" + str(correct/predictions.shape[0]))\n",
    "    \n",
    "    #Evaluating on Test set with best K value\n",
    "    knn = train_KNN(X_train, Y_train, best_K)\n",
    "    predictions = knn.predict(X_test)\n",
    "    correct = 0.0\n",
    "    for i in range(predictions.shape[0]):\n",
    "        if int_to_category(predictions[i]) == Y_decoder(Y_test[i])[0]:\n",
    "            correct += 1.0\n",
    "    if correct > max_score:\n",
    "        max_score = correct\n",
    "        best_K = k\n",
    "    print(\"Test set Performance with k = \" + str(best_K) + \":  \" + str(correct/predictions.shape[0]))\n",
    "        \n",
    "evaluate_KNN(X, Y)       \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing training data with 60-20-20 train-val-test split\n",
    "\n",
    "num_training = int(0.6 * X.shape[0])\n",
    "num_val_or_test = int(0.2 * X.shape[0])\n",
    "\n",
    "# shuffling with fixed seed\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# create big matrix and shuffle to ensure that things get shuffled properly\n",
    "# see https://stackoverflow.com/questions/35646908/numpy-shuffle-multidimensional-array-by-row-only-keep-column-order-unchanged\n",
    "\n",
    "total = np.hstack((X,Y))\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "np.random.shuffle(total)\n",
    "\n",
    "print X.shape\n",
    "print Y.shape\n",
    "\n",
    "# split back apart to partition into training, validation, and test sets\n",
    "\n",
    "X_new = total[:,0:X.shape[1]]\n",
    "Y_new = total[:,X.shape[1]:]\n",
    "\n",
    "#X_new = X\n",
    "#Y_new = Y # lol\n",
    "\n",
    "print X_new.shape\n",
    "print Y_new.shape\n",
    "\n",
    "print X[0]\n",
    "print Y[0]\n",
    "print X_new[0]\n",
    "print Y_new[0]\n",
    "\n",
    "X_train = X_new[0:num_training,:]\n",
    "Y_train = Y_new[0:num_training,:]\n",
    "\n",
    "X_val = X_new[num_training:num_training+num_val_or_test,:]\n",
    "Y_val = Y_new[num_training:num_training+num_val_or_test,:]\n",
    "\n",
    "X_test = X_new[num_training+num_val_or_test:,:]\n",
    "Y_test = Y_new[num_training+num_val_or_test:,:]\n",
    "\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "#u ready for some neural nets?\n",
    "\n",
    "batch_size = 2048\n",
    "epochs = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(activation='relu', input_shape=(13,), units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='relu', units=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(activation='softmax',units=9))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, Y_val))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
